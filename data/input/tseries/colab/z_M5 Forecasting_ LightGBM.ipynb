{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom  datetime import datetime, timedelta","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Prepare Datasets for Training"},{"metadata":{},"cell_type":"markdown","source":"## Define the correct data type for each column in the datasets"},{"metadata":{},"cell_type":"markdown","source":"### *calendar.csv*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correct data types for \"calendar.csv\"\ncalendarDTypes = {\"event_name_1\": \"category\", \n                  \"event_name_2\": \"category\", \n                  \"event_type_1\": \"category\", \n                  \"event_type_2\": \"category\", \n                  \"weekday\": \"category\", \n                  'wm_yr_wk': 'int16', \n                  \"wday\": \"int16\",\n                  \"month\": \"int16\", \n                  \"year\": \"int16\", \n                  \"snap_CA\": \"float32\", \n                  'snap_TX': 'float32', \n                  'snap_WI': 'float32' }\n\n# Read csv file\ncalendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\", \n                       dtype = calendarDTypes)\n\ncalendar[\"date\"] = pd.to_datetime(calendar[\"date\"])\n\n# Transform categorical features into integers\nfor col, colDType in calendarDTypes.items():\n    if colDType == \"category\":\n        calendar[col] = calendar[col].cat.codes.astype(\"int16\")\n        calendar[col] -= calendar[col].min()\n\ncalendar.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *sell_prices.csv*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correct data types for \"sell_prices.csv\"\npriceDTypes = {\"store_id\": \"category\", \n               \"item_id\": \"category\", \n               \"wm_yr_wk\": \"int16\",\n               \"sell_price\":\"float32\"}\n\n# Read csv file\nprices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\", \n                     dtype = priceDTypes)\n\n# Transform categorical features into integers\nfor col, colDType in priceDTypes.items():\n    if colDType == \"category\":\n        prices[col] = prices[col].cat.codes.astype(\"int16\")\n        prices[col] -= prices[col].min()\n        \nprices.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *sales_train_validation.csv*"},{"metadata":{"trusted":true},"cell_type":"code","source":"firstDay = 250\nlastDay = 1913\n\n# Use x sales days (columns) for training\nnumCols = [f\"d_{day}\" for day in range(firstDay, lastDay+1)]\n\n# Define all categorical columns\ncatCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n\n# Define the correct data types for \"sales_train_validation.csv\"\ndtype = {numCol: \"float32\" for numCol in numCols} \ndtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n\n# Read csv file\nds = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n                 usecols = catCols + numCols, dtype = dtype)\n\n# Transform categorical features into integers\nfor col in catCols:\n    if col != \"id\":\n        ds[col] = ds[col].cat.codes.astype(\"int16\")\n        ds[col] -= ds[col].min()\n        \nds = pd.melt(ds,\n             id_vars = catCols,\n             value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n             var_name = \"d\",\n             value_name = \"sales\")\n\n# Merge \"ds\" with \"calendar\" and \"prices\" dataframe\nds = ds.merge(calendar, on = \"d\", copy = False)\nds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n\nds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create features"},{"metadata":{},"cell_type":"markdown","source":"### Sales features"},{"metadata":{"trusted":true},"cell_type":"code","source":"dayLags = [7, 28]\nlagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\nfor dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n    ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n    \nwindows = [7, 28]\nfor window in windows:\n    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n        ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date features"},{"metadata":{"trusted":true},"cell_type":"code","source":"dateFeatures = {\"wday\": \"weekday\",\n                \"week\": \"weekofyear\",\n                \"month\": \"month\",\n                \"quarter\": \"quarter\",\n                \"year\": \"year\",\n                \"mday\": \"day\"}\n\nfor featName, featFunc in dateFeatures.items():\n    if featName in ds.columns:\n        ds[featName] = ds[featName].astype(\"int16\")\n    else:\n        ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove unnecessary rows and columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove all rows with NaN value\nds.dropna(inplace = True)\n\n# Define columns that need to be removed\nunusedCols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\ntrainCols = ds.columns[~ds.columns.isin(unusedCols)]\nX_train = ds[trainCols]\ny_train = ds[\"sales\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split dataset into train and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(777)\n\n# Define categorical features\ncatFeats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + \\\n           [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n\nvalidInds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\ntrainInds = np.setdiff1d(X_train.index.values, validInds)\n\ntrainData = lgb.Dataset(X_train.loc[trainInds], label = y_train.loc[trainInds], \n                        categorical_feature = catFeats, free_raw_data = False)\nvalidData = lgb.Dataset(X_train.loc[validInds], label = y_train.loc[validInds],\n                        categorical_feature = catFeats, free_raw_data = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del ds, X_train, y_train, validInds, trainInds ; gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n          \"objective\" : \"poisson\",\n          \"metric\" :\"rmse\",\n          \"force_row_wise\" : True,\n          \"learning_rate\" : 0.075,\n          \"sub_row\" : 0.75,\n          \"bagging_freq\" : 1,\n          \"lambda_l2\" : 0.1,\n          \"metric\": [\"rmse\"],\n          'verbosity': 1,\n          'num_iterations' : 1200,\n          'num_leaves': 128,\n          \"min_data_in_leaf\": 100,\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train LightGBM model\nm_lgb = lgb.train(params, trainData, valid_sets = [validData], verbose_eval = 20) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model\nm_lgb.save_model(\"model.lgb\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Last day used for training\ntrLast = 1913\n# Maximum lag day\nmaxLags = 57\n\n# Create dataset for predictions\ndef create_ds():\n    \n    startDay = trLast - maxLags\n    \n    numCols = [f\"d_{day}\" for day in range(startDay, trLast + 1)]\n    catCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    \n    dtype = {numCol:\"float32\" for numCol in numCols} \n    dtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n    \n    ds = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n                     usecols = catCols + numCols, dtype = dtype)\n    \n    for col in catCols:\n        if col != \"id\":\n            ds[col] = ds[col].cat.codes.astype(\"int16\")\n            ds[col] -= ds[col].min()\n    \n    for day in range(trLast + 1, trLast+ 28 +1):\n        ds[f\"d_{day}\"] = np.nan\n    \n    ds = pd.melt(ds,\n                 id_vars = catCols,\n                 value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n                 var_name = \"d\",\n                 value_name = \"sales\")\n    \n    ds = ds.merge(calendar, on = \"d\", copy = False)\n    ds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n    \n    return ds\n\ndef create_features(ds):          \n    dayLags = [7, 28]\n    lagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\n    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n        ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n\n    windows = [7, 28]\n    for window in windows:\n        for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n            ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())\n          \n    dateFeatures = {\"wday\": \"weekday\",\n                    \"week\": \"weekofyear\",\n                    \"month\": \"month\",\n                    \"quarter\": \"quarter\",\n                    \"year\": \"year\",\n                    \"mday\": \"day\"}\n\n    for featName, featFunc in dateFeatures.items():\n        if featName in ds.columns:\n            ds[featName] = ds[featName].astype(\"int16\")\n        else:\n            ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fday = datetime(2016,4, 25) \nalphas = [1.028, 1.023, 1.018]\nweights = [1/len(alphas)] * len(alphas)\nsub = 0.\n\nfor icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n\n    te = create_ds()\n    cols = [f\"F{i}\" for i in range(1,29)]\n\n    for tdelta in range(0, 28):\n        day = fday + timedelta(days=tdelta)\n        print(tdelta, day)\n        tst = te[(te['date'] >= day - timedelta(days=maxLags)) & (te['date'] <= day)].copy()\n        create_features(tst)\n        tst = tst.loc[tst['date'] == day , trainCols]\n        te.loc[te['date'] == day, \"sales\"] = alpha * m_lgb.predict(tst) # magic multiplier by kyakovlev\n\n    te_sub = te.loc[te['date'] >= fday, [\"id\", \"sales\"]].copy()\n    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n    te_sub.fillna(0., inplace = True)\n    te_sub.sort_values(\"id\", inplace = True)\n    te_sub.reset_index(drop=True, inplace = True)\n    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n    if icount == 0 :\n        sub = te_sub\n        sub[cols] *= weight\n    else:\n        sub[cols] += te_sub[cols]*weight\n    print(icount, alpha, weight)\n\n\nsub2 = sub.copy()\nsub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\nsub = pd.concat([sub, sub2], axis=0, sort=False)\nsub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}